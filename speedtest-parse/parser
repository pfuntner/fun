#! /usr/bin/env python3

import os
import re
import sys
import json
import signal
import logging
import argparse
import datetime

# import bruno_tools

"""
   Speedtest by Ookla

      Server: NeoNova (Randolph Telephone) - Asheboro, NC (id: 11814)
         ISP: Ting Fiber
Idle Latency:     8.99 ms   (jitter: 0.07ms, low: 8.96ms, high: 9.08ms)
    Download:   573.93 Mbps (data used: 675.1 MB)                                                   
                 47.92 ms   (jitter: 7.33ms, low: 8.02ms, high: 401.52ms)
      Upload:   500.64 Mbps (data used: 367.8 MB)                                                   
                 23.78 ms   (jitter: 3.14ms, low: 8.73ms, high: 60.89ms)
 Packet Loss:     0.0%
  Result URL: https://www.speedtest.net/result/c/ad6b00c5-3a74-4423-b8db-0a772647a5a0
"""

def clean(s):
  pattern = r'(\s|,)'
  return re.sub('^' + pattern, '', re.sub(pattern + '$', '', s))

def parse(section, additional_lines=0):
  ret = dict()
  for (pos, line) in enumerate(lines):
    match = re.search(r'^\s*' + section + ':(.*)$', ' '.join(lines[pos:pos+additional_lines+1]))
    if match:
      """
      Most of the sections have one or more sections enclosed by parentheses.  Let's knock those out first
      """
      sample = match.group(1)
      while True:
        match = re.search(r'^(.*)\(([^)]+)\)(.*)$', sample)
        if match:
          log.info(f'{section}: {match.groups()}')
          for (key, value) in re.findall(r'([a-z ]+):\s*(\S+)', match.group(2)):
            ret[clean(key)] = clean(value)
        else:
          break

        # We'll parse the remainder (before and after the parens) later
        sample = match.group(1) + ' ' + match.group(3)

      log.info(f'{sample=}')
      while True:
        """
        Now we can pull off more simple key/value pairs
        """
        match = re.search(r'([a-zA-Z0-9]+):\s*([a-zA-Z0-9 .]+)', sample)
        if match:
          ret[match.group(1)] = clean(match.group(2))
          sample = sample[:match.start(1)] + ' ' + sample[match.end(2):]
        break

      log.info(f'{sample=}')
      for (token1, token2) in re.findall('(\w+) (\w+)', re.sub(r'[()]', '', sample)):
        if token2.lower() == 'ms':
          ret['time'] = f'{token1} {token2}'
        elif token2.lower() == 'mbps':
          ret['speed'] = f'{token1} {token2}'
        else:
          ret[token2] = token1

      break
  return {section: ret}

parser = argparse.ArgumentParser(description=sys.argv[0])
parser.add_argument('-v', '--verbose', action='count', help='Enable debugging')
args = parser.parse_args()

logging.basicConfig(format='%(asctime)s %(levelname)s %(pathname)s:%(lineno)d %(msg)s')
log = logging.getLogger(sys.argv[0])
log.setLevel(logging.WARNING - (args.verbose or 0)*10)

signal.signal(signal.SIGPIPE, lambda signum, stack_frame: exit(0))

if sys.stdin.isatty():
  parser.error('You must redirect stdin')

now = datetime.datetime.utcnow()

output = sys.stdin.read()
lines = output.splitlines()

"""
The 'rough' key value pairs can parse out a lot of basic information
"""

rough_kvs = {key: value for (key, value) in re.findall(r'^\s*([-_.A-Za-z0-9 ]*):\s+(.*\S)', output, flags=re.MULTILINE)}
"""
('Server', 'NeoNova (Randolph Telephone) - Asheboro, NC (id: 11814)')
('ISP', 'Ting Fiber')
('Idle Latency', '8.99 ms   (jitter: 0.07ms, low: 8.96ms, high: 9.08ms)')
('Download', '573.93 Mbps (data used: 675.1 MB)')
('Upload', '500.64 Mbps (data used: 367.8 MB)')
('Packet Loss', '0.0%')
('Result URL', 'https://www.speedtest.net/result/c/ad6b00c5-3a74-4423-b8db-0a772647a5a0')
"""
log.info(f'{rough_kvs=}')

result = {
  'timestamp': now.isoformat() + 'Z',
  'server': rough_kvs.get('Server'),
  'isp': rough_kvs.get('ISP'),
  'packet loss': rough_kvs.get('Packet Loss'),
  'result url': rough_kvs.get('Result URL'),
}

"""
Other sections are more complicated - there are two or more datums across one or more lines
"""

result.update(parse('Idle Latency'))
result.update(parse('Download', 1))
result.update(parse('Upload', 1))

json.dump(result, sys.stdout)
print()
