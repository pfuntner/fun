#! /usr/bin/env python

import re
import sys
import json
import logging
import argparse

class Filter(object):
  regexp = re.compile('^([^=]+)(?:=(.*))?$')

  def __init__(self, filter):
    match = self.regexp.search(filter)
    log.debug('match: {groups}'.format(groups=match.groups() if match else None))
    valid = False
    if match:
      valid = True
      try:
        self.name = re.compile(match.group(1))
        log.debug('name pattern: {pattern}'.format(pattern=self.name.pattern))
      except Exception as e:
        sys.stderr.write('{pattern!r} is an invalid regular expression'.format(pattern=match.group(1)))
        valid = False

      if match.group(2):
        try:
          self.value = re.compile(match.group(2))
          log.debug('value pattern: {pattern}'.format(pattern=self.value.pattern))
        except Exception as e:
          sys.stderr.write('{pattern!r} is an invalid regular expression'.format(pattern=match.group(2)))
          valid = False
      else:
        self.value = None

    if not valid:
      parser.error('Filter {filter!r} is invalid'.format(**locals()))
    
def load(stream):
  data = stream.read()

  if args.yaml:
    return yaml.load(data)

  try:
    ret = json.loads(data)
  except Exception as e:
    log.debug('Unable to load entire stream: {e!s}'.format(**locals()))
  else:
    log.info('Parsed entire stream')
    if type(ret) in [list, dict]:
      log.info('There are {count} elements'.format(count=len(ret)))
    log.debug('Loaded {ret}'.format(**locals()))
    return ret

  buf = ''
  ret = []

  for line in data.splitlines():
    buf += ('\n' if buf else '') + line
    try:
      datum = json.loads(buf)
    except Exception as e:
      pass
    else:
      log.info('Parsed item {pos}'.format(pos=len(ret)))
      log.debug('Loaded {datum}'.format(**locals()))
      ret.append(datum)
      buf = ''

  if buf:
    total = len(data)
    sys.stderr.write('Failed to load entire file\n')
    sys.stderr.write('{count:,} objects were loaded\n'.format(count=len(ret)))
    sys.stderr.write('{processed:,} bytes out of {total:,} were loaded\n'.format(processed=total-len(buf), **locals()))
    exit(1)

  return ret

def defaultWriter(root):
  print json.dumps(root, indent=2, sort_keys=True)

def linearWriter(root):
  if isinstance(root, list):
    for datum in root:
      print json.dumps(datum)
  else:
    sys.stderr.write('Can only use --linear on lists\n')
    exit(1)

def flatWriter(root, path=[]):
  if type(root) in [list, dict]:
    if args.all:
      print '/{path}{final}'.format(path='/'.join(path), final='/' if path else '')
    for key in range(len(root)) if isinstance(root, list) else root.keys():
      flatWriter(root[key], path + [str(key)])
  else:
    print '/{path} {root}'.format(path='/'.join(path), root=root)

def findpath(root, path_pattern, path=[]):
  ret = []

  log.debug('Entering ({root}, {pattern}, {path})'.format(pattern=path_pattern.pattern, **locals()))

  curr = '/' + ('/'.join(path))
  if path_pattern.search(curr):
    ret.append(root)

  if type(root) in [list, dict]:
    for key in range(len(root)) if isinstance(root, list) else root.keys():
      ret += findpath(root[key], path_pattern, path + [str(key)])

  if not path:
    if len(ret) == 0:
      ret = None
    elif len(ret) == 1:
      ret = ret[0]

  log.debug('Leaving ({root}, {pattern}, {path}) => {ret}'.format(pattern=path_pattern.pattern, **locals()))

  return ret

def applyFilters(root, from_list=False):
  log.debug('applying filters to {root}'.format(**locals()))
  if isinstance(root, list):
    key = 0
    while key < len(root):
      ret = applyFilters(root[key], from_list=True)
      if ret:
        root[key] = ret
        key += 1
      else:
        root.pop(key)
  elif isinstance(root, dict):
    keys = root.keys()
    for key in keys:
      ret = applyFilters(root[key])
      if ret:
        root[key] = ret
      else:
        del root[key]

    if not any([type(value) in [list,dict] for value in root.values()]):
      """
      We will only apply the filters if there are no lists or dicts in the root.  If there are such objects,
      they must have alerady passed the filters and their parents should be pass so they children are visible.
      """
      for filter in includes:
        if filter.value is None:
          if not any([filter.name.search(key) for key in root.keys()]):
            root = None
            break
        else:
          found = False
          for (key, value) in root.items():
            if type(value) not in [dict, list]:
              value = str(value)
              log.debug('Testing {key}={value!r} against key pattern {key_pat!r} and value pattern {value_pat!r}'.format(
                key_pat=filter.name.pattern,
                value_pat=filter.value.pattern,
                **locals()
              ))
              if filter.name.search(key) and filter.value.search(value):
                log.debug('{key}={value!r} matches the include filter'.format(**locals()))
                found = True
                break
          if not found:
            log.debug('Exclusion: {root} does not match the include filter'.format(**locals()))
            root = None
            break

      for filter in excludes:
        if filter.value is None:
          if any([filter.name.search(key) for key in root.keys()]):
            root = None
            break
        else:
          for (key, value) in root.items():
            if type(value) not in [dict, list]:
              value = str(value)
              if filter.name.search(key) and filter.value.search(value):
                log.debug('Exclusion: {key}={value!r} matches the exclude filter'.format(**locals()))
                root = None
                break
          if root is None:
            break
  elif from_list:
    root=None
    
  if not root:
    root = None

  log.debug('after applying filters: {root}'.format(**locals()))
  return root

parser = argparse.ArgumentParser(description='JSON tool')
group = parser.add_mutually_exclusive_group()
group.add_argument('-f', '--flatten', dest='flatten', action='store_true', help='Flatten elements')
group.add_argument('-l', '--linear', dest='linear', action='store_true', help='Print elements linearly')

parser.add_argument('-y', '--yaml', dest='yaml', action='store_true', help='Read input yaml file')
parser.add_argument('-a', '--all', dest='all', action='store_true',
                    help='Show "directories" of the JSON with --flatten')
parser.add_argument('-F', '--file', dest='file', help='Input file')
parser.add_argument('-i', '--include', dest='includes', action='append', help='Specify required attributes')
parser.add_argument('-x', '--exclude', dest='excludes', action='append', help='Specify unwanted attributes')
parser.add_argument('-v', '--verbose', dest='verbose', action='count', help='Enable more debugging')

parser.add_argument('path', nargs='?', help='Path to desired object(s)')
args = parser.parse_args()

yaml = None
if args.yaml:
  # let's import yaml module only when the option is specified, in case the module is not installed
  yaml = __import__('yaml')

logging.basicConfig(format='%(asctime)s %(levelname)s %(pathname)s:%(lineno)d %(msg)s')
log = logging.getLogger()
log.setLevel(logging.WARNING - (args.verbose or 0)*10)

if args.flatten:
  writer = flatWriter
elif args.linear:
  writer = linearWriter
else:
  writer = defaultWriter

root = None
if args.file:
  with open(args.file) as stream:
    root = load(stream)
else:
  if sys.stdin.isatty():
    parser.error('stdin must be directed if --file is not specified')
  root = load(sys.stdin)

if args.path:
  root = findpath(root, re.compile((('^' if args.path.startswith('/') else '/') + args.path + '$').replace('/*/', '/[^/]+/')))

includes = [Filter(filter) for filter in (args.includes or [])]
excludes = [Filter(filter) for filter in (args.excludes or [])]
root = applyFilters(root)

writer(root)
